[[concurrency-solutions]]
=== 동시성 문제의 해법

한 명 이상이 _동시에_ 파일이나 디렉토리의 이름을 변경하려는 경우 문제가 발생한다.((("concurrency", "solving concurrency issues")))((("relationships", "solving concurrency issues")))
당신이 수십만 개의 파일을 가지고 있는 `/clinton` 디렉토리의 이름을 변경하고, 
다른 사용자는 `/clinton/projects/elasticsearch/README.txt` 라는 파일의 이름을 변경한다고 가정해보자. 
다른 사용자의 변경 요청이 당신의 디렉토리 이름 변경 요청 이후에 시작했더라도, 아마 더 빨리 완료될 것이다.

이 경우 다음 두 가지 중 하나가 발생할 것이다.

*   당신이 `version` number를 사용하기로 결정했다면, 다른 사용자가 `README.asciidoc` 으로 이름을 변경할 때, 
    당신의 대량의 이름 변경이 버전 충돌로 실패할 것이다.

*   당신이 version number를 사용하지 않았다면, 당신의 변경 요청이 다른 사용자의 변경 사항을 덮어 쓸 것이다.

문제는 Elasticsearch가 http://en.wikipedia.org/wiki/ACID_transactions[ACID transactions].((("ACID transactions")))을 지원하지 않는 다는 것이다.
개별 document에 대한 변경은 ACID를 보장하지만, 여러 document에 대한 변경은 보장하지 않는다.

주 데이터 저장소가 RDB이고, Elasticsearch를 단순히 검색엔진((("relational databases", "Elasticsearch used with")))이나 성능 향상의 수단으로 사용하고 있다면,
당신의 변경사항을 우선 RDB에 반영하고, 그것이 성공한 뒤에 Elasticsearch로 복제해라. 
이것은 RDB에서 이용할 수 있는 ACID Transaction의 혜택을 받는 방식이고, Elasticsearch에 대한 모든 변경 사항은 올바른 순서로 일어난다. 
즉, 동시성은 RDB에서 처리한다.

만약 관계형 저장소를 사용하지 않는다면, 이런 동시성 이슈를 Elasticsearch에서 처리해야 한다. 
Elasticsearch는 아래와 같은 모두 어떤 잠금(locking)의 형태를 포함하는 3가지 유용한 해법을 제시할 것이다.

* Global Locking
* Document Locking
* Tree Locking

[TIP]
==================================================

아래에 언급된 해법은, Elasticsearch 대신에 외부의 다른 시스템을 통해 동일한 원리를 적용함으로써 구현될 수도 있다

==================================================

[[global-lock]]
==== Global Locking

항상 단일 프로세스만 변경을 하도록 허용하여, 동시성 문제를 완벽하게 피할 수 있다.((("locking", "global lock")))((("global lock")))
대부분의 변경은 몇 개의 파일만을 포함하고, 매우 빠르게 완료된다. 
최상위 단계 디렉토리의 이름 변경은 더 오랫동안 다른 모든 변경 모두를 막을(block) 수 있다.
하지만 이런 동작은 그리 자주 발생하지는 않는다.

Elasticsearch에서 document 수준의 변경은 ACID를 보장하기 때문에, global lock document의 존재 여부를 사용할 수 있다.
잠금(lock)을 요청하기 위해서, global-lock document를 `생성(create)` 해 보자.

[source,json]
--------------------------
PUT /fs/lock/global/_create
{}
--------------------------

이 `create` 요청이 충돌 예외로 실패하면, 그것은 다른 프로세스가 이미 global lock을 사용하고 있고, 
나중에 다시 시도해야 된다는 것을 의미한다. 만약 성공한다면, 이제 global lock의 소유자로서, 
변경 작업을 계속할 수 있다. 작업이 완료되면, global lock document를 삭제하여, 잠금을 해제해야 한다.

[source,json]
--------------------------
DELETE /fs/lock/global
--------------------------

변경이 얼마나 자주 일어나고, 얼마나 오래 걸리느냐에 따라, global lock은 시스템의 성능을 크게 제한할 수 있다. 
잠금을 더 세분화하여, 병렬 처리를 증가시킬 수 있다.

[[document-locking]]
==== Document Locking

전체 file system에 대한 잠금 대신, 위와 동일한 방법으로 개별 document를 잠글 수 있다.((("locking", "document locking")))((("document locking")))
프로세스는 변경에 영향을 받는 모든 document의 ID를 가져오기 위하여, <<scan-scroll,scan-and-scroll>>을 사용할 수 있고, 
그들 각각에 대한 잠금 파일을 생성해야 한다.

[source,json]
--------------------------
PUT /fs/lock/_bulk
{ "create": { "_id": 1}} <1>
{ "process_id": 123    } <2>
{ "create": { "_id": 2}}
{ "process_id": 123    }
...
--------------------------
<1> `lock` document의 ID는 잠겨야 하는 파일의 ID와 동일해야 한다.
<2> `process_id` 는 변경을 수행하려는 프로세스를 나타내는 어떤 고유한 ID이다

특정 파일이 이미 잠겨 있다면, `bulk` 요청의 일부는 실패하고, 다시 시도해야 한다.

물론, _모든_ 파일을 잠그려고 다시 시도하면, 위에서 사용했던 `create` 문장은 이미 잠긴 어떤 파일에 대해 실패할 것이다.
간단한 `create` 문장 대신, `upsert` 파라메터를 사용한, `update` 요청과 아래 `script` 가 필요하다. 

[source,groovy]
--------------------------
if ( ctx._source.process_id != process_id ) { <1>
  assert false;  <2>
}
ctx.op = 'noop'; <3>
--------------------------
<1> `process_id` 는 script에 전달할 파라메터이다.
<2> `assert false` update 실패의 원인인 exception을 발생시킨다.
<3> `op` 를 `update` 에서 `noop` 로 바꾸어, update 요청이 변경되는 것을 방지한다. 하지만 여전히 success를 반환한다.

전체 `update` 요청은 아래와 같다.

[source,json]
--------------------------
POST /fs/lock/1/_update
{
  "upsert": { "process_id": 123 },
  "script": "if ( ctx._source.process_id != process_id ) 
  { assert false }; ctx.op = 'noop';"
  "params": {
    "process_id": 123
  }
}
--------------------------

document가 아직 존재하지 않는 경우, `upsert` document는 이전에 사용했던 `create` 요청과 거의 동일하게 insert 된다. 
그러나 document가 존재한다면, script는 document에 저장된 `process_id` 를 확인할 것이다. 
만약 동일하다면, 업데이트(`noop`)를 중단하고, success를 반환할 것이다. 
만약 다르면, `assert false` 는 exception을 발생시켜, 잠금이 실패했다는 것을 알린다.

모든 잠금이 성공적으로 생성되면, 이름 변경 작업을 시작할 수 있다. 
그 후, 모든 잠금을 해제해야 한다.((("delete-by-query request"))) 이는 `delete-by-query` 요청을 통해 가능하다.

[source,json]
--------------------------
POST /fs/_refresh <1>

DELETE /fs/lock/_query
{
  "query": {
    "term": {
      "process_id": 123
    }
  }
}
--------------------------
<1> `refresh` 호출은 모든 `lock` document가 `delete-by-query` 요청에 보이도록 보장한다.

document 수준의 잠금은 세분화된 액세스 제어가 가능하지만, 수백 만개의 잠금 파일을 생성하려면, 많은 비용이 들 수 있다.
디렉토리 tree 같은 예와 같은 특정 시나리오에서, 훨씬 적은 작업으로 세분화된 잠금을 하는 것이 가능하다.

[[tree-locking]]
==== Tree Locking

이전의 옵션에서처럼, 관련된 모든 document를 잠그기 보다는, 디렉토리 tree의 일부만 잠글 수도 있다.((("locking", "tree locking")))
이름을 변경하려는 파일이나 디렉토리를 배타적으로 액세스해야 할 필요가 있다. 
이것은 _exclusive lock_ document로 가능하다.

[source,json]
--------------------------
{ "lock_type": "exclusive" }
--------------------------

그리고 _shared lock_ document로 모든 부모 디렉토리와 잠금을 공유해야 한다

[source,json]
--------------------------
{
  "lock_type":  "shared",
  "lock_count": 1 <1>
}
--------------------------
<1> `lock_count` 는 shared lock을 가지고 있는 프로세스의 수를 기록한다.

`/clinton/projects/elasticsearch/README.txt` 의 이름을 변경하려는 프로세스는, 해당 파일에 대한 _exclusive_ lock과
`/clinton`, `/clinton/projects`, `/clinton/projects/elasticsearch` 에 대한 _shared_ lock 이 필요하다.

간단한 `create` 요청으로 exclusive lock은 충분히 가능하지만, 
shared lock은 추가로 몇 가지를 구현하기 위한 script로 된 update가 필요하다

[source,groovy]
--------------------------
if (ctx._source.lock_type == 'exclusive') {
  assert false; <1>
}
ctx._source.lock_count++ <2>
--------------------------
<1> `lock_type` 이 `exclusive` 이면, `assert` 문장은 exception(업데이트 요청이 실패한 원인)을 발생시킨다.
<2> 그렇지 않으면, `lock_count` 를 증가시킨다.

이 script는 `lock` document가 이미 존재하는 경우를 처리하지만, 
아직 존재하지 않는 경우를 처리하기 위해서는 `upsert` document가 필요하다. 
전체 update 요청은 아래와 같다.

[source,json]
--------------------------
POST /fs/lock/%2Fclinton/_update <1>
{
  "upsert": { <2>
    "lock_type":  "shared",
    "lock_count": 1
  },
  "script": "if (ctx._source.lock_type == 'exclusive') 
  { assert false }; ctx._source.lock_count++"
}
--------------------------
<1> document의 ID는 `%2fclinton` 으로 URL-Encode된 `/clinton` 이다. 
<2> `upsert` document는 document가 아직 존재하지 않으면 insert된다.

모든 부모 디렉토리에 대한 shared lock 확보에 성공하면, 파일 자체에 대한 exclusive lock의 `create` 를 시도한다.

[source,json]
--------------------------
PUT /fs/lock/%2Fclinton%2fprojects%2felasticsearch%2fREADME.txt/_create
{ "lock_type": "exclusive" }
--------------------------

이제, 누군가가 `/clinton` 디렉토리의 이름을 변경하려 한다면, 해당 경로에 대한 exclusive lock을 얻어야 한다.

[source,json]
--------------------------
PUT /fs/lock/%2Fclinton/_create
{ "lock_type": "exclusive" }
--------------------------

동일한 ID를 가진 `lock` document가 이미 존재하기 때문에 이 요청은 실패한다. 
다른 사용자는 우리의 연산이 종료되고, 잠금이 해제될 때까지 기다려야 한다. exclusive lock은 삭제만 가능하다.

[source,json]
--------------------------
DELETE /fs/lock/%2Fclinton%2fprojects%2felasticsearch%2fREADME.txt
--------------------------

shared lock은, `lock_count` 를 감소시키는 또 다른 script가 필요하다. 
그리고 count가 0이 되면 `lock` document를 삭제한다.

[source,groovy]
--------------------------
if (--ctx._source.lock_count == 0) {
  ctx.op = 'delete' <1>
}
--------------------------
<1> `lock_count` 가 `0` 이 되면, `ctx.op` 는 `update` 에서 `delete` 로 변경된다.

이 업데이트 요청은 각각의 부모 디렉토리에 대해, 역순(가장 긴 것부터 가장 짧은 것까지)으로 동작해야 한다.

[source,json]
--------------------------
POST /fs/lock/%2Fclinton%2fprojects%2felasticsearch/_update
{
  "script": "if (--ctx._source.lock_count == 0) { ctx.op = 'delete' } "
}
--------------------------

Tree locking은 최소한의 노력으로, 세분화된 동시성 제어를 가능하게 한다. 
물론, 이것이 모든 상황에 적합하지는 않다. 이 데이터 모델이 동작하려면,
디렉토리 tree같은 액세스 경로(access path)의 일종을 가지고 있어야 한다.

[NOTE]
=====================================

“잠금을 가진 프로세스가 죽었을 경우 어떤 일이 발생하는가” 라는 잠금과 관련된 골치 아픈 문제는 
3가지 옵션(global, document, tree)중 어떤 것으로도 처리하지 못한다.

예기치 않은 프로세스의 죽음은 2가지 문제를 남긴다.

* 죽은 프로세스가 가지고 있던 lock을 해제할 수 있는 방법이 있는가?
* 죽은 프로세스가 완료하지 못한 변경 사항을 정리할 방법은 무엇인가?

이런 주제는 이 책의 범위를 벗어난다. 그러나, 잠금을 사용하기로 결정했다면, 그것들에 대해 생각해야 한다.

=====================================

비정규화는 많은 프로젝트에서 좋은 선택이지만, 잠금 방식에 대한 필요성이 구현을 복잡하게 만들 수 있다.
Elasticsearch는 관련된 entity를 다루기 위해서 2가지 모델(_nested objects_, _parent-child relationship_)을 제공한다.
